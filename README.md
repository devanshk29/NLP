#  AI Text  Detection

**Devansh Kantesaria (2022112003)**  
*IIIT Hyderabad*

---

##  Project Overview

This project presents multiple architectures for detecting whether a given piece of text was written by a **human** or **generated by AI**. The key focus is on designing systems that can accurately differentiate between AI-generated and human-written text using a blend of linguistic, stylistic, and semantic features.

Three distinct approaches were implemented and compared:

1. **Initial Approach** – A weighted ensemble combining sentence-level BiLSTM and document-level MLP.
2. **GAN-based Approach** – A Generative Adversarial Network for adversarial feature learning.
3. **Lightweight Approach** – A fast, interpretable, and efficient hybrid system using stylometry and traditional embeddings.

---

##  Methodologies

###  Initial Approach: Weighted Ensemble Model

- **Preprocessing**: HTML cleaning, URL/email removal, case & unicode normalization.
- **Embedding**: RoBERTa-based embeddings, reduced from 768D to 30D.
- **Architecture**:
  - BiLSTM for sequential sentence-level patterns.
  - MLP for document-level semantics.
  - Weighted ensemble using a learnable parameter to balance both outputs.

### ⚔ GAN-Based Architecture

- **Motivation**: Capture deeper linguistic differences using adversarial learning.
- **Pipeline**:
  - **DistilRoBERTa** for base embeddings (frozen).
  - **Generator** transforms embeddings for enhanced representation.
  - **Discriminator** evaluates authenticity using:
    - Generated embeddings
    - Stylometric features (e.g., sentence length, type-token ratio).
- **Training**:
  - Adversarial loop with separate learning rates.
  - Balanced update schedule (Discriminator : Generator = 5:1).
  - t-SNE visualization & feature importance analysis.

###  Lightweight Detector

- **Designed for Efficiency** with solid accuracy and interpretability.
- **Feature Set**:
  - Stylometry: POS distribution, punctuation patterns, Yule’s K, etc.
  - Embeddings: TF-IDF with bigrams, reduced via a neural network.
- **Architecture**:
  - BiLSTM for sentence-level embeddings.
  - Feed-forward networks for stylometry and full-text embedding.
  - Feature fusion → final binary classification.

---

##  Dataset

Combined and curated from multiple sources:

- [Open-GPT-Text](https://drive.google.com/drive/folders/1uc9kB5Nm7zx1UMJcpeGnjU7GI6xWNxNy)
- [Open-Web-Text](https://drive.google.com/drive/folders/1raU6ST48KziMc6C8Kt8wcufJWPH4HKUo)
- [AI vs Human Essays Dataset](https://www.kaggle.com/datasets/shanegerami/ai-vs-human-text)
- [Combined AI-Human Text Dataset](https://www.kaggle.com/datasets/architpethani/combined-dataset-ai-human)

 **Final Stats**:
- 47,000 balanced samples  
- Labels: 1 for AI-generated, 0 for human-written

---

##  Results

| **Approach**          | **Accuracy** | **F1 Score** | **AUC-ROC** |
|-----------------------|--------------|--------------|-------------|
| Initial (BiLSTM+MLP)  | 0.4435       | 0.4560       | 0.4784      |
| GAN-Based             | 0.5460       | 0.5320       | 0.5782      |
| Lightweight Approach  | **0.6227**   | **0.6553**   | **0.6114**  |

---

##  Key Insights

- **Stylometric analysis** proved highly useful in identifying AI-generated content.
- **Strategic masking** helped the GAN generalize better.
- The **lightweight approach** achieved the best performance with minimal computational overhead.

---

##  Practical Applications

- Academic integrity checking (e.g., AI-generated essays)
- Media and journalism for content authenticity
- Content moderation on platforms
- Detection of synthetic news
- Social media trend analysis

---

## ⚠ Limitations

- GAN-based training is **computationally intensive** and **unstable**.
- Domain generalization remains a challenge.
- Short texts may reduce model reliability.

---

##  Technologies Used

- **Python**, **PyTorch**
- **Transformers**: RoBERTa, DistilRoBERTa
- **Libraries**: SpaCy, BeautifulSoup, Scikit-learn, NumPy, t-SNE, Regex
- **Techniques**: BiLSTM, MLP, TF-IDF, Dropout, BatchNorm, AdamW

---

##  Future Work

- Incorporate few-shot learning for low-data scenarios
- Improve cross-domain generalization
- Create a unified API for real-world integration

---
